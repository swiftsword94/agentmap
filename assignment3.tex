\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{program}

\title{Assignment 3: Bayesian Inference, Temporal State Estimation and Decision Making under Uncertainty}
\author{Alex Smirnov, Scott Reyes}
\date{April 11, 2017}							% Activate to display a given date or no date

\begin{document}
\maketitle
%\section{}
%\subsection{}
\begin{flushleft}

\section*{Problem 1:}
\subsection*{a}
The probability that all five of the Boolean variables are simultaneously true is:\\

$P(A)=0.2$\\
$P(B)=0.5$\\
$P(C)=0.8$\\
$P(D \mid A \wedge B)=0.1$\\
$P(E \mid B \wedge C)=0.3$\\ 
$P(A \wedge B)=0.1$\\
$P(A \wedge B \wedge C)=0.08$\\
$P(A \wedge B \wedge C)\times P(D \mid A \wedge B)=0.008$\\
$P(A \wedge B \wedge C)\times P(D \mid A \wedge B) \times P(E \mid B \wedge C)=0.0024$\\
\subsection*{b}
The probability that all five of the Boolean variables are simultaneously false is:\\
$P(\neg A)=0.8$\\
$P(\neg B)=0.5$\\
$P(\neg C)=0.2$\\
$P(\neg D \mid \neg A \wedge \neg B)=0.1$\\
$P(\neg E \mid \neg B \wedge \neg C)=0.8$\\
$P(\neg A \wedge \neg B)=0.4$\\
$P(\neg A \wedge \neg B \wedge \neg C)=0.08$\\
$P(\neg A \wedge \neg B \wedge \neg C) \times P( \neg D \mid \neg A \wedge \neg B)=0.008$\\
$P(\neg A \wedge \neg B \wedge \neg C)\times P(\neg D \mid \neg A \wedge \neg B) \times P(\neg E \mid \neg B \wedge \neg C)=0.0064$\\
\subsection*{c}
$P(\neg A)=0.8$\\
$P(D \wedge B)=0.7$\\
$P(D \wedge B \mid \neg A)=0.6$\\
$P(\neg A \mid D \wedge B)=\frac{0.8*0.6}{0.7}=0.686$\\
\section*{Problem 2:}
\subsection*{a}
\subsection*{b}
\subsection*{c}
\section*{Problem 3:}
\subsection*{a}
Prove:
$$P(X \mid MB(X)) = \alpha P(X \mid U_{1}, ..., U_{m}) \prod_{Yi} P(Y_{i} \mid Z_{i}, ...)$$
Definition of Bayesian network:
$$(x_{1},x_{2},...,x_{n})=\prod_{i=1}^{n} P(x_{i} \mid parents(X_{i}))$$
via product rule:
$$(x_{1},x_{2},...,x_{n})=P(x_{1} \mid x_{n-1}, ..., x_{1})P(x_{n-1},...,x_{1})$$
Definition of Markov Assumption:
$$P(X_{t} \mid X_{0:t-1}) = P(X_{t} \mid X_{t-1})$$
Using the Markov assumption on the Bayesian network lets all nodes be conditionally independent from the other nodes in the graph given the Markov blanket because X's children  conditionally depend on X as well as the child's parents, and x depends on its parents.
\subsection*{b}
$$P(Rain \mid Sprinkler=true \wedge WetGrass=true)$$
MCMC would solve this by trying fixing sprinkler and wet grass to true while testing rain by calculating the probability repeatedly randomly changing the non fixed variable values. In the case above, there would be 4 states to take into consideration. Cloudy=T/F, Rain=T/F.
\subsection*{c}
\section*{Problem 4:}
\subsection*{a}
\subsection*{b}
\subsection*{c}
\subsection*{d}
\section*{Problem 5 - Programming Component:}
\subsection*{a}
\subsection*{b}
\subsection*{c - Generating Ground Truth Data}
\subsection*{d - Filtering and Viterbi Algorithms in Large Maps}
\subsection*{e}
\subsection*{f}
\subsection*{g}
\subsection*{h - Computational Approximations}
\end{flushleft}
\end{document}  